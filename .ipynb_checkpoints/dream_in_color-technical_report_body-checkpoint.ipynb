{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dream in Color - Technical Report Body (No Appendices)\n",
    "- A project by Laura Markham Prescott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "<a href=\"#intro\">Introduction</a>\n",
    "\n",
    "<a href=\"#materials\">Materials and Methods</a>\n",
    "\n",
    "<a href=\"#model_building\">Model Building</a>\n",
    "\n",
    "<a href=\"#image_prep\">Image Preprocessing and Data Preparation</a>\n",
    "\n",
    "<a href=\"#architecture\">Convonet Architecture</a>\n",
    "\n",
    "<a href=\"#evaluation\">Model Evaluation</a>\n",
    "\n",
    "<a href=\"#selection\">Model Selection</a>\n",
    "\n",
    "<a href=\"#production\">Production</a>\n",
    "\n",
    "<a href=\"#features\">Extra Features</a>\n",
    "\n",
    "<a href=\"#conclusions\">Conclusions and Future Work</a>\n",
    "\n",
    "<a href=\"#resources\">Some Resources</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<a id=\"intro\"></a>\n",
    "In traditional wedding planning, the bride chooses one color and style of dress for all of her bridesmaids to wear. A new trend called \"Mismatched Bridesmaids\" diverges from the aforementioned tradition and is growing in popularity. To achieve the \"Mismatched Bridesmaid\" look, each bridesmaid has a different style and/or color of dress that all fit within a common theme or palette. \n",
    "\n",
    "\n",
    "## Traditional Bridesmaids\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT3QrBz1S6V22JX2oZDZwLZHxG_IRMu4420_UrwYkYMSlPBTUHaCg\"> \n",
    "\n",
    "## Mismatched Bridesmaids\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTLxG6H-DCM2kLr2DwX_NRvKzNvZMfoAK91XurYbYVTEeCMQSNRog\">\n",
    "<img src=\"http://cdn-img.instyle.com/sites/default/files/styles/622x350/public/images/2016/06/063016-mismatched-bridesmaids-lead.jpg?itok=2gRgIn8Y\">\n",
    "\n",
    "Currently there are no tools to make this look easy to achieve. Most online bridesmaid dress retailers don't provide enough variety and flexibility of color choice for dress sorting/identification to fit this new trend. Likewise, many retail websites don't have products to fit bridesmaids of all shapes, sizes, and budgets. In the end, one group of bridesmaids will end up visiting several different retailers, online and in person, contacting the bride over and over to make sure they get it right.\n",
    "\n",
    "To address this problem, I aimed to do the following:\n",
    "- create a machine learning algorithm that can classify dresses into several, specific color classes\n",
    "- apply this model to dresses currently available for purchase online\n",
    "- make the application available for brides and bridesmaids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials and Methods\n",
    "<a id=\"materials\"></a>\n",
    "I approached this project as an image classification problem. I wanted to be able to classify dresses based on the pictures available from online retailers. Images are available for every dress sold online, whereas a description or color-name is not always available or consistent across retailers. In the end, it's all about how the dresses look, and that is best evaluated and compared via images!\n",
    "\n",
    "## Web Development\n",
    "Robb Prescott did the web development work for this project. We discussed visions for the final web application from the beginning so our work would be guided with the same goals in mind. He built a labeling website for data collection and a final website for the product, all discussed below.\n",
    "\n",
    "## Data Collection\n",
    "A lot of images are required to train a successful image classification algorithm. I used two bulk image downloading applications to gather images from the web:\n",
    "- Bulk Download Images(ZIG)\n",
    "- Fatkun Batch Download Image\n",
    "\n",
    "Model building images were gathered from google image searches, google shopping searches, as well as some online clothing retailer websites. Quality of images ranged widely from retail/professional quality to cell phone pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Label Selection\n",
    "I looked through several websites for ideas on how to organize and display color and color options on the web. Robb and I decided to use the resources available here for the project: \n",
    "https://www.materialpalette.com/colors\n",
    "\n",
    "Robb provided the json data from the above website with information for all the colors as hexidecimal codes. I converted the hex codes to RGB values, created a function for plotting chosen colors, and narrowed my color labels down from 254 (number of colors from the material palette website) to 64 color labels for my project. Code is shown in <a href=\"app_a\">Appendix A: Color Selection</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1', 'b2', 'c3', 'd4', 'e5', 'f6', 'g7', 'h8', 'i9', 'j10', 'k11', 'l12', 'm13', 'n14']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAGKCAYAAACxYB0nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njrOwSZIkdZyFTZIkqeP+P4T2iMAWvkFQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d626710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yellow = df[df['family'] == 'yellow']\n",
    "yellow = yellow.reset_index()\n",
    "\n",
    "#I viewed colors like this\n",
    "plot_colors(yellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"after_a\"></a>\n",
    "### Labeling Data\n",
    "After the colors were selected, Robb set up a website with heroku for labeling the data:\n",
    "- color.suprinfinity.com\n",
    "\n",
    "New users are prompted to set up an account. User accounts were helpful for tracking the applied labels, but this system also caused some issues with Mechanical Turk later down the line.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-01+at+11.14.51+AM.png\" style=\"width:300px;\">\n",
    "\n",
    "After creating an account, the user could label images with our labeling system. An image is shown on the left side of the screen, and labels to choose from are on the right.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.08.13+PM.png\" style=\"width:600px;\">\n",
    "\n",
    "Clicking one of the color groups shown above reveals more specific colors to choose from for labeling. There are 64 total color labels.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.07.33+PM.png\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once an image is labeled, the data is collected in a Postgres database. Other labels (aside from color) were collected for potential use in the project:\n",
    "- Image Details labels helped me exclude certain types of pictures from my models\n",
    "- Length and Fabric labels were not used in the current project, but may be used for future improvements/features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I collected **18,630** images, which are stored in an Amazon Web Services (AWS) S3 bucket. In order to get enough images labeled for the project, I outsourced labeling tasks through **Amazon Mechanical Turk (MTurk)**.\n",
    "\n",
    "<img src=\"https://onlinegrindseason.files.wordpress.com/2015/02/pp_img_3_col_mechanical_turk_good_logo_no_artificial_2378x171.png\">\n",
    "\n",
    "While MTurk was effective for getting a large quantity of labels completed, the quality of labeling work was not good. To get better labels from MTurk in the future, I would:\n",
    "- set up labeling directly through AWS on MTurk instead of my own outside site (avoids violating terms of service)\n",
    "- collect different types of labels in separate tasks\n",
    "    - i.e. color labeling as one task; image type labeling as a separate task; length labeling as separate task.\n",
    "- establish my reputation on MTurk\n",
    "- pay more money per task\n",
    "- only allow proven workers\n",
    "- make larger tasks\n",
    "\n",
    "### Cleaning Data - Labels\n",
    "\n",
    "After using MTurk, I spent several days re-labeling (cleaning) the dataset before it was in acceptable shape for modeling. It is important to have a way to easily display all the image data and their corresponding information for effective re-labeling. I used the 'Admin Dresses' page of our labeling website to accomplish this task. This feature allows me to view all the dresses and their labels, as well as view all images under a specific label. For example, the screenshot below shows the first few dresses that are labeled with the color 'teal5'. I manually changed labels in our postgreSQL database and used some python code to generate SQL queries for bulk relabeling (<a href=\"app_b\">Appendix B: SQL</a>).\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Untitled+drawing+(1).jpg\" style=\"width:300;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"after_b\"></a>\n",
    "### Cleaning Data - to csv\n",
    "\n",
    "Data from the database also needed to be cleaned before images could be downloaded and used for modeling. <a href=\"app_c\">Appendix C: Data to csv</a> <a id=\"after_c\"></a>shows how data from the database was cleaned and prepared for modeling. This included: \n",
    "- Excluding 'bad' and 'bride' images\n",
    "    - 'Bad' and 'bride' images were excluded due to their quality and potential negative impacts during modeling.\n",
    "- Excluding 'multicolor' dresses\n",
    "    - Labeling for these dresses was inconsistent and innacurate. This is an interesting problem to tackle for another project.\n",
    "- Reconciling multiple labels\n",
    "    - I was originally intending to have every image labeled more than once for data validation. However, given the time and scope of the project, that was not an attainable goal. Robb re-programmed the labeling site to default select images that hadn't been labeled yet. There was some overlap before this setting was adjusted as well as when multiple people were labeling simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "<a id=\"model_building\"></a>\n",
    "In order to create a viable product to address the stated problem, I wanted my model to have a higher number of color classes than available on typical clothing retail websites. I used between **30 to 35 color classes** in all of my models. These color classes were constructed of different combinations of the original 64 color labels. The model building process involved dynamic movement between building/running/evaluating models, re-cleaning data for clearer class separation, and combining or separating color labels for different combinations.\n",
    "\n",
    "\n",
    "## K Nearest Neighbors\n",
    "\n",
    "I applied K Nearest Neighbors without much success. For 31 color classes, 3.7% was the highest accuracy I achieved. See <a href=\"app_d\">Appendix D: K Nearest Neighbors</a> <a id=\"after_d\"></a> for some code and results. Given the computational process of K Nearest Neighbors, I did not expect great results. This algorithm would not handle variation in backgrounds or subject well, but I wanted to apply it as a sort of secondary baseline.\n",
    "\n",
    "**True Baseline** was between 4% to 5% in all my models due to some minor class imbalance. The Black and Navy color classes had more images than others. Adjusting for class imbalance is another strategy I would like to try in the future to improve model performance which will require more labeled images.\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "Convolutional Neural Networks (convonets) are effective for image classification problems, thus I spent the bulk of my modeling time building these for my application. While collecting data from MTurk, I built a preliminary 12 color classification convonet on a small sample of labeled images. This helped me test my modeling pipeline as well as locate and resolve weak points in my process.\n",
    "\n",
    "### Google Cloud Compute Engine\n",
    "First, I needed more computing power before increasing the number/size of images and the width/depth of my convonet. I applied for access to a graphics processing unit (GPU) from Google Cloud Compute and AWS. I decided to use Google Cloud Compute Engine because of their prompt reply to my request for a GPU. I set up an Ubuntu virtual machine (8 vCPUs, 52 GB memory) with one NVIDIA Tesla K80 GPU and set up tensorflow-gpu with Keras for modeling.\n",
    "\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQlsZKALQ85fGkobZpv4rC4wUAgmIlyPSkLNe2IyWiuH-eNlwHT\" style=\"width:300;\">\n",
    "<img src=\"data:image/png;base64,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\" style=\"width:300;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing and Data Preparation\n",
    "<a id=\"image_prep\"></a>\n",
    "Due to the relatively small number of images for each class, I used Keras preprocessing tools (ImageDataGenerator) to augment images for modeling. Below is an example of how this Keras tool works. By stretching, flipping, and applying other modifications, the same image can be used multiple times, effectively increasing my sample size for training the model.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Data+Augmentation.jpg\" style=\"width:600;\">\n",
    "\n",
    "In order to use the ImageDataGenerator feature of keras, images had to be stored according to a specific file structure (example shown below). Thus, each time I made adjustments to image labels or color class combinations, images needed to be re-downloaded and arranged within the appropriate file structure. In order to accomplish this more effectively, I used python to generate command line scripts to help automate the following:\n",
    "1. Create a .txt file for image downloading\n",
    "2. Train test split by color group\n",
    "3. Populate .txt files with appropriate URLs for downloading\n",
    "4. Create appropriate directories for file storage\n",
    "5. Download images to correct directories\n",
    "6. Resize, center, and fill white on each image\n",
    "\n",
    "Code for the above process is shown in <a href=\"app_e\">Appendix E: Image Download and Preparation</a>. <a id=\"after_e\"></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Example file structure\n",
    "\n",
    "data/\n",
    "    train/\n",
    "        aqua/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        beige/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        ...\n",
    "    test/\n",
    "        aqua/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        beige/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        ...        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convonet Architecture\n",
    "<a id=\"architecture\"></a>\n",
    "I tried several variations on parameters, and the most effective convonet architecture for this project is shown and described below. It typically required between 75 to 150 epochs to converge without overfitting to the training data. More details on the final model architecture and performance are shown in <a href=\"app_f\">Appendix F: 35 Color Class Convonet</a>.<a id=\"after_f\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 297, 297, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 146, 146, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 146, 146, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                5017664   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 35)                2275      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 35)                0         \n",
      "=================================================================\n",
      "Total params: 5,048,579\n",
      "Trainable params: 5,048,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "<a id=\"evaluation\"></a>\n",
    "To evaluate performance of each model, I first looked at typical performance metrics:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "\n",
    "These metrics helped me refine initial model parameters, adjust color class segmentations, and identify high and low performing models without overly time-consuming evaluation. Via this process, I created an effective convonet with 31 color classes (Model_31).\n",
    "\n",
    "**Model_31**\n",
    "- Overall Model Accuracy: 81 %\n",
    "- Average Precision:      81 %\n",
    "- Average Recall:         80 %\n",
    "- Average F1:             81 %\n",
    "\n",
    "To further evaluate Model_31, I looked at performance within each color group:\n",
    "- Create a dataframe for each color group\n",
    "- View model predictions within each color group\n",
    "- View images with incorrect predicted values\n",
    "\n",
    "With this process, I made two key observations about images the model labeled incorrectly, and I addressed each accordingly:\n",
    "1. **The model was often predicting a very close color group**\n",
    "    - For the purposes of my product, this is an acceptable outcome. For instance, a light yellow dress may be classified as a yellow dress. It is still within the same color family and will likely be seen by bridesmaids perusing for light yellow dresses. However, a light yellow dress classified incorrectly as emerald green is not acceptable for several reasons.\n",
    "    - Due to the above, I created my own **\"Close Scoring\"** metrics to evaluate models. I calculated a \"Close Overall Model Accuracy\" and a \"Close Recall\" score within 1 and 2 color groups. This involved counting any classification within 1 or 2 close color groups as a \"Close Positive\" in place of a \"True Positive\". Code shown in Appendix G for the final selected model (more description and link below).\n",
    "    \n",
    "    \n",
    "2. **The model was actually correctly labeling some of the images (I had incorrectly labeled them)**\n",
    "    - I discovered several images in color groups had been mislabeled before modeling. For example, the model classified several grey dresses as beige. When I opened those images, they were actually beige dresses that I had labeled incorrectly.\n",
    "    - Due to this discovery in evaluating Model_31, I went back and further cleaned my data before building more models.\n",
    "    \n",
    "The below image demonstrates both stated observations. It shows images from the **CORAL** group that were incorrectly labeled as dark_pink or light_pink.\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-06+at+1.06.43+PM.png\" style=\"width:500;\">\n",
    "\\*above images and classification actually from final selected model (Model_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "<a id=\"selection\"></a>\n",
    "After further cleaning labels and trying several more models, I used the above process to select my final model: **Model_35**. Convonet details are described in <a href=\"app_f\">Appendix F</a>. Evaluation metrics are shown in <a href=\"app_g\">Appendix G: Model_35 Evaluation Metrics</a>.<a id=\"after_g\"></a>\n",
    "\n",
    "**Model_35 Score Summary:**\n",
    "- Overall Model Accuracy:   79 %\n",
    "- Average Precision:        80 %\n",
    "- Average Recall:           79 %\n",
    "- Average F1:               78 %\n",
    "- Average Close (1) Recall: 87%\n",
    "- Average Close (2) Recall: 93%\n",
    "\n",
    "The below image shows True and Close(2) recall scores across color groups.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-06+at+2.50.48+PM.png\" style=\"width:500;\">\n",
    "\n",
    "Nude\n",
    "- Based on scores, the model does not appear to classify Nude dresses effectively. Scores are likely low due to **overlap in labeling** with close color groups. The Nude, Blush, Beige, Golden Tan, and Rose color groups all contain very similar dress colors. These are some of the most common bridesmaid dress colors, so I wanted to have separate options for them if possible. **Better labeling may improve scores.** Though the model doesn't appear to perform well on this category, it actually does an effective job when put into production.\n",
    "\n",
    "Latte\n",
    "- Scores in this color category are also low, but likely for a different reason: **class imbalance**. The image below shows each color category and the total number of images I collected in each category. Latte (brown) had the fewest images. However, Chocolate (dark_brown) and Golden Tan also had much fewer images than other color categories but performed well overall. **Alleviating class imbalance might improve model scores across color groups**. Again, the model actually did an effective job categorizing Latte dresses when put into production.\n",
    "\n",
    "Silver\n",
    "- High scores in this category indicate the model should categorize Silver dresses accurately. When put into production, the model did not perform as well as expected for this category. This is again likely due to mislabeling within the category and also some potential background and image quality noise. More training images and better labeling would likely improve this performance\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/class+imbalance.jpg\" style=\"width:300;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production: \n",
    "<a id=\"production\"></a>\n",
    "http://dreamincolor.suprinfinity.com\n",
    "\n",
    "In order to create a viable product using my model, I needed to collect data on currently available dresses to categorize and display to users. I scraped data from the following six major online bridesmaid dress retailers:\n",
    "- Nordstrom\n",
    "- Weddington Way\n",
    "- Lulus\n",
    "- Asos\n",
    "- The Dessy Group\n",
    "- The Knot\n",
    "\n",
    "I used Xpath, scrapy spiders, and other strategies to gather data from these websites. For every dress, I collected the following:\n",
    "- Dress image link\n",
    "- Price\n",
    "- Link to the product\n",
    "- Product name\n",
    "- Retailer name\n",
    "\n",
    "After cleaning and compiling the data, I used my model to predict color classes from the images and provided everything to Robb for integration with the website. Robb completed all the web development work for dreamincolor.suprinfinity.com. I stored production images in another AWS S3 bucket for production access, and the website was set up through Heroku with a postgres database.\n",
    "\n",
    "I collected a total of **3670 dresses** for display on the website.\n",
    "\n",
    "Visitors to the site can select up to 5 color categories to view at one time. The site displays all the dresses within the chosen color category and all information associated with each dress. When the user clicks on a dress, it takes her directly to the purchase page from the retailer.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-06+at+3.23.33+PM.png\" style=\"width:600;\">\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/17+emerald.png\" style=\"width:600;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image shows an example of how dresses are displayed when a color is chosen. <a href=\"app_h\">Appendix H: Model Classification Snapshot</a> <a id=\"after_h\"></a> shows a screenshot of each color category on the website. These snapshots show the classification of every image by the chosen model. No changes have been made to dress classifications at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extra Features\n",
    "<a id=\"features\"></a>\n",
    "## Find Similar Dresses\n",
    "\n",
    "From the last Dense layer of the Model_35 convonet, I extracted a 64 dimensional vector for every production image. This was accomplished by building a net with the same architecture, inserting weights from the layers of Model_35, and outputing the vector from the first Dense layer for each image (omitting the softmax output layer). With the set of 64 dimensional vectors, I created a cosine similarity matrix. This matrix gives a \"score\" for how similar dresses are based on the convonet output vector. Code is shown in <a href=\"app_i\">Appendix I: Cosine Similarity Matrix</a>.<a id=\"after_i\"></a>\n",
    "\n",
    "My goal with the cosine similarity matrix was to create a feature for the website to allow users to view dresses similar to the ones they like. My hope was that, within the convolutions of the neural network, some dress features other than color might be captured (i.e. length, fabric texture, sheen). I looked at a few examples, and this appears to have been successful.\n",
    "\n",
    "Below, I chose a long, champagne-colored, sequine dress (outlined image top left). The top most similar dresses from the matrix were all long, very similar in color, several with some sort of sheen, texture, or sequins.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.10.49+PM.png\" style=\"width:600;\">\n",
    "\n",
    "In the second test (below) I chose another long, sequin dress. This reference dress (outlined image top left) is navy, but the model misclassified it as black. Interestingly, all the most similar dresses from the cosine similarity matrix were correctly classified as navy. They were also long and some had sequins or lace.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.10.59+PM.png\" style=\"width:600;\">\n",
    "\n",
    "The effectiveness of the cosine similarity matrix for finding similar dresses appears fairly successful. Performance on a larger scale still needs to be assessed. It would be useful to find the weak points in this feature, identifying at what number of dresses is there a noticeable divergence in style/color similarity. I imagine this will be heavily influenced by the number of dresses available in the reference dress color category.\n",
    "\n",
    "## Other Similar Products\n",
    "\n",
    "From hair accessories to statement jewelry all the way down to toenail polish and matching wedges, there is a lot more to a bridesmaid's ensemble than her dress alone. Likewise, groomsmen are expected to match, too (think bowties, suspenders, pocket squares, socks). With this in mind, I wanted to see if my convonet could be used on other wedding-party related products. \n",
    "\n",
    "I tested this theory on bowties first. Retail images for ties and bowties are usually focused on the product, with a simple background and not much other noise. Model_35 was very effective in identifying the color class of a small sample of bowties. The image below shows the bowtie and the model predicted color class. Further evaluation of effectiveness is warranted, and this looks like a very promising potential feature for the website!\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.11.22+PM.png\" style=\"width:600;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Future Work\n",
    "<a id=\"conclusions\"></a>\n",
    "Using a convolutional neural network to classify dress images was an effecive approach for accomplishing my goals. Data collection, cleaning, and labeling was the most important and time-intensive part of the project. The final website provides many more color choices than typical online retailers, and it is a great starting point with potential for improvements in many areas.\n",
    "\n",
    "## Future Model Improvements\n",
    "\n",
    "### Data Collection, Label Cleaning\n",
    "Model performance is only as good as the data allows. The cleaner the data and better segmented the color classes, the better the model will perform. Likewise, more data will help performance.\n",
    "\n",
    "A Better Labeling Approach\n",
    "- Currently, I can only view dresses on the \"Admin Dresses\" site that have received a label from our website. To improve the data collection process, I'd like to create a tag for \"unlabeled\", which allows me to view all the images through my website and more quickly add labels to the database manually.\n",
    "\n",
    "Class Imbalance\n",
    "- Resolving some of the class imbalance may improve the performance of the convonet. I will need to collet and label more images in the lacking color classes.\n",
    "\n",
    "Background Subtraction/RGB Histograms\n",
    "- I may try applying background subtraction to the images, then labeling based on most frequent RGB values. I could use the images I already have in each color class to help identify RGB ranges for labeling.\n",
    "\n",
    "Label Like-Images\n",
    "- Leveraging the current data-set may also be possible for gathering more/better/different data. Instead of having people label with color swatches, they could select images with like-colors. This process could be used to label by color groups and could also be used for different types of convonet modeling.\n",
    "\n",
    "### More Models\n",
    "\n",
    "General Improvements\n",
    "- After collecting more data and improving the labels, I'd like to build a similar convonet that performs better than the current one. With more time and work, that is definitely possible.\n",
    "\n",
    "Localization/Similarity\n",
    "- A convonet that can identify the location of a dress (or other product) in an image could be very useful for this application. This would require a different kind of data labeling. With localization abilities and data on alike-images, it may be possible to build a model that can take in an image and return like-dresses.\n",
    "\n",
    "Transfer Learning\n",
    "- I may be able to achieve greater accuracy in labeling with transfer learning (i.e. using a pre-trained architecture like VGG-16 or Inception V3). I had originally intended to try this, which is why I chose 299x299 for my input image size. Overall, I don't think the improvements I would get from transfer learning would be worthwhile until the dataset is improved (cleaner labeling, more balanced classes).\n",
    "\n",
    "## Future Website Improvements\n",
    "\n",
    "I have a lot of ideas for improving the website which were not within the scope of the original project. Ideas for website improvement include:\n",
    "\n",
    "More retailers\n",
    "- Partnerships to eliminate need for scraping\n",
    "- Wider selection of dresses in general\n",
    "    \n",
    "Automated data collection process\n",
    "\n",
    "Special features (described above)\n",
    "- Click for similar dresses\n",
    "- Matching accessories (bowties etc.)\n",
    "\n",
    "Bride Accounts\n",
    "- Bride sets up her \"shop\" and invites bridesmaids\n",
    "       - chooses colors\n",
    "       - removes dresses she doesn't like\n",
    "- Drag and drop image slots to lock in purchased dresses\n",
    "- Image upload if a bridesmaid gets a dress somewhere else\n",
    "\n",
    "Color-coded like buttons (by bridesmaid)\n",
    "\n",
    "Channeled dress viewing\n",
    "- When a color is selected, it displays column-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Resources\n",
    "<a id=\"resources\"></a>\n",
    "**Image Downloading**\n",
    "\n",
    "Bulk Download Images(ZIG): https://chrome.google.com/webstore/detail/bulk-download-imageszig/gfjhimhkjmipphnaminnnnjpnlneeplk?hl=en\n",
    "\n",
    "Fatkun Batch Download Image: https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf?hl=en\n",
    "\n",
    "\n",
    "**Stanford cs231 notes and lecture videos**\n",
    "\n",
    "http://cs231n.github.io/\n",
    "\n",
    "https://www.youtube.com/watch?v=yp9rwI_LZX8&index=1&list=PLjX3tKChumyCOstk6GO8PeEjwmcz7jWia\n",
    "\n",
    "**Keras tutorial**\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dream in Color\n",
    "## A project by Laura Markham Prescott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "In traditional wedding planning, the bride chooses one color and style of dress for all of her bridesmaids to wear. A new trend called \"Mismatched Bridesmaids\" diverges from the aforementioned tradition and is growing in popularity. To achieve the \"Mismatched Bridesmaid\" look, each bridesmaid has a different style and/or color of dress that all fit within a common theme or palette. \n",
    "\n",
    "\n",
    "## Traditional Bridesmaids\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT3QrBz1S6V22JX2oZDZwLZHxG_IRMu4420_UrwYkYMSlPBTUHaCg\"> \n",
    "\n",
    "## Mismatched Bridesmaids\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTLxG6H-DCM2kLr2DwX_NRvKzNvZMfoAK91XurYbYVTEeCMQSNRog\">\n",
    "<img src=\"http://cdn-img.instyle.com/sites/default/files/styles/622x350/public/images/2016/06/063016-mismatched-bridesmaids-lead.jpg?itok=2gRgIn8Y\">\n",
    "\n",
    "Currently there are no tools to make this look easy to achieve. Most online bridesmaid dress retailers don't provide enough variety and flexibility of color choice for dress sorting/identification to fit this new trend. Likewise, many retail websites don't have products to fit bridesmaids of all shapes, sizes, and budgets. In the end, one group of bridesmaids will end up visiting several different retailers, online and in person, contacting the bride over and over to make sure they get it right.\n",
    "\n",
    "To address this problem, I aimed to do the following:\n",
    "- create a machine learning algorithm that can classify dresses into several, specific color classes\n",
    "- apply this model to dresses currently available for purchase online\n",
    "- make the application available for brides and bridesmaids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials and Methods\n",
    "\n",
    "I approached this project as an image classification problem. I wanted to be able to classify dresses based on the pictures available from online retailers. Images are available for every dress sold online, whereas a description or color-name is not always available or consistent across retailers. In the end, it's all about how the dresses look, and that is best evaluated and compared via images!\n",
    "\n",
    "## Web Development\n",
    "Robb Prescott did the web development work for this project. We discussed visions for the final web application from the beginning so our work would be guided with the same goals in mind. He built a labeling website for data collection and a final website for the product, all discussed below.\n",
    "\n",
    "## Data Collection\n",
    "A lot of images are required to train a successful image classification algorithm. I used two bulk image downloading applications to gather images from the web:\n",
    "- Bulk Download Images(ZIG)\n",
    "- Fatkun Batch Download Image\n",
    "\n",
    "Model building images were gathered from google image searches, google shopping searches, as well as some online clothing retailer websites. Quality of images ranged widely from retail/professional quality to cell phone pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Label Selection\n",
    "I looked through several websites for ideas on how to organize and display color and color options on the web. Robb and I decided to use the resources available here for the project: \n",
    "https://www.materialpalette.com/colors\n",
    "\n",
    "Robb provided the json data from the above website with information for all the colors as hexidecimal codes. I converted the hex codes to RGB values, created a function for plotting chosen colors, and narrowed my color labels down from 254 (number of colors from the material palette website) to 64 color labels for my project. Code is shown in <a href=\"app_a\">Appendix A: Color Selection</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1', 'b2', 'c3', 'd4', 'e5', 'f6', 'g7', 'h8', 'i9', 'j10', 'k11', 'l12', 'm13', 'n14']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAGKCAYAAACxYB0nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njrOwSZIkdZyFTZIkqeP+P4T2iMAWvkFQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d626710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yellow = df[df['family'] == 'yellow']\n",
    "yellow = yellow.reset_index()\n",
    "\n",
    "#I viewed colors like this\n",
    "plot_colors(yellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"after_a\"></a>\n",
    "### Labeling Data\n",
    "After the colors were selected, Robb set up a website with heroku for labeling the data:\n",
    "- color.suprinfinity.com\n",
    "\n",
    "New users are prompted to set up an account. User accounts were helpful for tracking the applied labels, but this system also caused some issues with Mechanical Turk later down the line.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-01+at+11.14.51+AM.png\" style=\"width:300px;\">\n",
    "\n",
    "After creating an account, the user could label images with our labeling system. An image is shown on the left side of the screen, and labels to choose from are on the right.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.08.13+PM.png\" style=\"width:600px;\">\n",
    "\n",
    "Clicking one of the color groups shown above reveals more specific colors to choose from for labeling. There are 64 total color labels.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.07.33+PM.png\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once an image is labeled, the data is collected in a Postgres database. Other labels (aside from color) were collected for potential use in the project:\n",
    "- Image Details labels helped me exclude certain types of pictures from my models\n",
    "- Length and Fabric labels were not used in the current project, but may be used for future improvements/features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I collected **18,630** images, which are stored in an Amazon Web Services (AWS) S3 bucket. In order to get enough images labeled for the project, I outsourced labeling tasks through **Amazon Mechanical Turk (MTurk)**.\n",
    "\n",
    "<img src=\"https://onlinegrindseason.files.wordpress.com/2015/02/pp_img_3_col_mechanical_turk_good_logo_no_artificial_2378x171.png\">\n",
    "\n",
    "While MTurk was effective for getting a large quantity of labels completed, the quality of labeling work was not good. To get better labels from MTurk in the future, I would:\n",
    "- set up labeling directly through AWS on MTurk instead of my own outside site (avoids violating terms of service)\n",
    "- collect different types of labels in separate tasks\n",
    "    - i.e. color labeling as one task; image type labeling as a separate task; length labeling as separate task.\n",
    "- establish my reputation on MTurk\n",
    "- pay more money per task\n",
    "- only allow proven workers\n",
    "- make larger tasks\n",
    "\n",
    "### Cleaning Data - Labels\n",
    "\n",
    "After using MTurk, I spent several days re-labeling (cleaning) the dataset before it was in acceptable shape for modeling. It is important to have a way to easily display all the image data and their corresponding information for effective re-labeling. I used the 'Admin Dresses' page of our labeling website to accomplish this task. This feature allows me to view all the dresses and their labels, as well as view all images under a specific label. For example, the screenshot below shows the first few dresses that are labeled with the color 'teal5'. I manually changed labels in our postgreSQL database and used some python code to generate SQL queries for bulk relabeling (<a href=\"app_b\">Appendix B: SQL</a>).\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Untitled+drawing+(1).jpg\" style=\"width:300;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"after_b\"></a>\n",
    "### Cleaning Data - to csv\n",
    "\n",
    "Data from the database also needed to be cleaned before images could be downloaded and used for modeling. <a href=\"app_c\">Appendix C: Data to csv</a> <a id=\"after_c\"></a>shows how data from the database was cleaned and prepared for modeling. This included: \n",
    "- Excluding 'bad' and 'bride' images\n",
    "    - 'Bad' and 'bride' images were excluded due to their quality and potential negative impacts during modeling.\n",
    "- Excluding 'multicolor' dresses\n",
    "    - Labeling for these dresses was inconsistent and innacurate. This is an interesting problem to tackle for another project.\n",
    "- Reconciling multiple labels\n",
    "    - I was originally intending to have every image labeled more than once for data validation. However, given the time and scope of the project, that was not an attainable goal. Robb re-programmed the labeling site to default select images that hadn't been labeled yet. There was some overlap before this setting was adjusted as well as when multiple people were labeling simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "In order to create a viable product to address the stated problem, I wanted my model to have a higher number of color classes than available on typical clothing retail websites. I used between **30 to 35 color classes** in all of my models. These color classes were constructed of different combinations of the original 64 color labels. The model building process involved dynamic movement between building/running/evaluating models, re-cleaning data for clearer class separation, and combining or separating color labels for different combinations.\n",
    "\n",
    "\n",
    "## K Nearest Neighbors\n",
    "\n",
    "I applied K Nearest Neighbors without much success. For 31 color classes, 3.7% was the highest accuracy I achieved. See <a href=\"app_d\">Appendix D: K Nearest Neighbors</a> <a id=\"after_d\"></a> for some code and results. Given the computational process of K Nearest Neighbors, I did not expect great results. This algorithm would not handle variation in backgrounds or subject well, but I wanted to apply it as a sort of secondary baseline.\n",
    "\n",
    "**True Baseline** was between 4% to 5% in all my models due to some minor class imbalance. The Black and Navy color classes had more images than others. Adjusting for class imbalance is another strategy I would like to try in the future to improve model performance which will require more labeled images.\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "Convolutional Neural Networks (convonets) are effective for image classification problems, thus I spent the bulk of my modeling time building these for my application. While collecting data from MTurk, I built a preliminary 12 color classification convonet on a small sample of labeled images. This helped me test my modeling pipeline as well as locate and resolve weak points in my process.\n",
    "\n",
    "### Google Cloud Compute Engine\n",
    "First, I needed more computing power before increasing the number/size of images and the width/depth of my convonet. I applied for access to a graphics processing unit (GPU) from Google Cloud Compute and AWS. I decided to use Google Cloud Compute Engine because of their prompt reply to my request for a GPU. I set up an Ubuntu virtual machine (8 vCPUs, 52 GB memory) with one NVIDIA Tesla K80 GPU and set up tensorflow-gpu with Keras for modeling.\n",
    "\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQlsZKALQ85fGkobZpv4rC4wUAgmIlyPSkLNe2IyWiuH-eNlwHT\" style=\"width:300;\">\n",
    "<img src=\"data:image/png;base64,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\" style=\"width:300;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing and Data Preparation\n",
    "Due to the relatively small number of images for each class, I used Keras preprocessing tools (ImageDataGenerator) to augment images for modeling. Below is an example of how this Keras tool works. By stretching, flipping, and applying other modifications, the same image can be used multiple times, effectively increasing my sample size for training the model.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Data+Augmentation.jpg\" style=\"width:600;\">\n",
    "\n",
    "In order to use the ImageDataGenerator feature of keras, images had to be stored according to a specific file structure (example shown below). Thus, each time I made adjustments to image labels or color class combinations, images needed to be re-downloaded and arranged within the appropriate file structure. In order to accomplish this more effectively, I used python to generate command line scripts to help automate the following:\n",
    "1. Create a .txt file for image downloading\n",
    "2. Train test split by color group\n",
    "3. Populate .txt files with appropriate URLs for downloading\n",
    "4. Create appropriate directories for file storage\n",
    "5. Download images to correct directories\n",
    "6. Resize, center, and fill white on each image\n",
    "\n",
    "Code for the above process is shown in <a href=\"app_e\">Appendix E: Image Download and Preparation</a>. <a id=\"after_e\"></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Example file structure\n",
    "\n",
    "data/\n",
    "    train/\n",
    "        aqua/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        beige/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        ...\n",
    "    test/\n",
    "        aqua/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        beige/\n",
    "            001.jpg\n",
    "            002.jpg\n",
    "            ...\n",
    "        ...        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convonet Architecture\n",
    "\n",
    "I tried several variations on parameters, and the most effective convonet architecture for this project is shown and described below. It typically required between 75 to 150 epochs to converge without overfitting to the training data. More details on the final model architecture and performance are shown in <a href=\"app_f\">Appendix F: 35 Color Class Convonet</a>.<a id=\"after_f\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 297, 297, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 146, 146, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 146, 146, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                5017664   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 35)                2275      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 35)                0         \n",
      "=================================================================\n",
      "Total params: 5,048,579\n",
      "Trainable params: 5,048,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "To evaluate performance of each model, I first looked at typical performance metrics:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "\n",
    "These metrics helped me refine initial model parameters, adjust color class segmentations, and identify high and low performing models without overly time-consuming evaluation. Via this process, I created an effective convonet with 31 color classes (Model_31).\n",
    "\n",
    "**Model_31**\n",
    "- Overall Model Accuracy: 81 %\n",
    "- Average Precision:      81 %\n",
    "- Average Recall:         80 %\n",
    "- Average F1:             81 %\n",
    "\n",
    "To further evaluate Model_31, I looked at performance within each color group:\n",
    "- Create a dataframe for each color group\n",
    "- View model predictions within each color group\n",
    "- View images with incorrect predicted values\n",
    "\n",
    "With this process, I made two key observations about images the model labeled incorrectly, and I addressed each accordingly:\n",
    "1. **The model was often predicting a very close color group**\n",
    "    - For the purposes of my product, this is an acceptable outcome. For instance, a light yellow dress may be classified as a yellow dress. It is still within the same color family and will likely be seen by bridesmaids perusing for light yellow dresses. However, a light yellow dress classified incorrectly as emerald green is not acceptable for several reasons.\n",
    "    - Due to the above, I created my own **\"Close Scoring\"** metrics to evaluate models. I calculated a \"Close Overall Model Accuracy\" and a \"Close Recall\" score within 1 and 2 color groups. This involved counting any classification within 1 or 2 close color groups as a \"Close Positive\" in place of a \"True Positive\". Code shown in Appendix G for the final selected model (more description and link below).\n",
    "    \n",
    "    \n",
    "2. **The model was actually correctly labeling some of the images (I had incorrectly labeled them)**\n",
    "    - I discovered several images in color groups had been mislabeled before modeling. For example, the model classified several grey dresses as beige. When I opened those images, they were actually beige dresses that I had labeled incorrectly.\n",
    "    - Due to this discovery in evaluating Model_31, I went back and further cleaned my data before building more models.\n",
    "    \n",
    "The below image demonstrates both stated observations. It shows images from the **CORAL** group that were incorrectly labeled as dark_pink or light_pink.\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-06+at+1.06.43+PM.png\" style=\"width:500;\">\n",
    "\\*above images and classification actually from final selected model (Model_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "After further cleaning labels and trying several more models, I used the above process to select my final model: **Model_35**. Convonet details are described in <a href=\"app_f\">Appendix F</a>. Evaluation metrics are shown in <a href=\"app_g\">Appendix G: Model_35 Evaluation Metrics</a>.<a id=\"after_g\"></a>\n",
    "\n",
    "**Model_35 Score Summary:**\n",
    "- Overall Model Accuracy:   79 %\n",
    "- Average Precision:        80 %\n",
    "- Average Recall:           79 %\n",
    "- Average F1:               78 %\n",
    "- Average Close (1) Recall: 87%\n",
    "- Average Close (2) Recall: 93%\n",
    "\n",
    "The below image shows True and Close(2) recall scores across color groups.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-06+at+2.50.48+PM.png\" style=\"width:500;\">\n",
    "\n",
    "Nude\n",
    "- Based on scores, the model does not appear to classify Nude dresses effectively. Scores are likely low due to **overlap in labeling** with close color groups. The Nude, Blush, Beige, Golden Tan, and Rose color groups all contain very similar dress colors. These are some of the most common bridesmaid dress colors, so I wanted to have separate options for them if possible. **Better labeling may improve scores.** Though the model doesn't appear to perform well on this category, it actually does an effective job when put into production.\n",
    "\n",
    "Latte\n",
    "- Scores in this color category are also low, but likely for a different reason: **class imbalance**. The image below shows each color category and the total number of images I collected in each category. Latte (brown) had the fewest images. However, Chocolate (dark_brown) and Golden Tan also had much fewer images than other color categories but performed well overall. **Alleviating class imbalance might improve model scores across color groups**. Again, the model actually did an effective job categorizing Latte dresses when put into production.\n",
    "\n",
    "Silver\n",
    "- High scores in this category indicate the model should categorize Silver dresses accurately. When put into production, the model did not perform as well as expected for this category. This is again likely due to mislabeling within the category and also some potential background and image quality noise. More training images and better labeling would likely improve this performance\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/class+imbalance.jpg\" style=\"width:300;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production: \n",
    "\n",
    "http://dreamincolor.suprinfinity.com\n",
    "\n",
    "In order to create a viable product using my model, I needed to collect data on currently available dresses to categorize and display to users. I scraped data from the following six major online bridesmaid dress retailers:\n",
    "- Nordstrom\n",
    "- Weddington Way\n",
    "- Lulus\n",
    "- Asos\n",
    "- The Dessy Group\n",
    "- The Knot\n",
    "\n",
    "I used Xpath, scrapy spiders, and other strategies to gather data from these websites. For every dress, I collected the following:\n",
    "- Dress image link\n",
    "- Price\n",
    "- Link to the product\n",
    "- Product name\n",
    "- Retailer name\n",
    "\n",
    "After cleaning and compiling the data, I used my model to predict color classes from the images and provided everything to Robb for integration with the website. Robb completed all the web development work for dreamincolor.suprinfinity.com. I stored production images in another AWS S3 bucket for production access, and the website was set up through Heroku with a postgres database.\n",
    "\n",
    "I collected a total of **3670 dresses** for display on the website.\n",
    "\n",
    "Visitors to the site can select up to 5 color categories to view at one time. The site displays all the dresses within the chosen color category and all information associated with each dress. When the user clicks on a dress, it takes her directly to the purchase page from the retailer.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-06-06+at+3.23.33+PM.png\" style=\"width:600;\">\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/17+emerald.png\" style=\"width:600;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image shows an example of how dresses are displayed when a color is chosen. <a href=\"app_h\">Appendix H: Model Classification Snapshot</a> <a id=\"after_h\"></a> shows a screenshot of each color category on the website. These snapshots show the classification of every image by the chosen model. No changes have been made to dress classifications at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extra Features\n",
    "\n",
    "## Find Similar Dresses\n",
    "\n",
    "From the last Dense layer of the Model_35 convonet, I extracted a 64 dimensional vector for every production image. This was accomplished by building a net with the same architecture, inserting weights from the layers of Model_35, and outputing the vector from the first Dense layer for each image (omitting the softmax output layer). With the set of 64 dimensional vectors, I created a cosine similarity matrix. This matrix gives a \"score\" for how similar dresses are based on the convonet output vector. Code is shown in <a href=\"app_i\">Appendix I: Cosine Similarity Matrix</a>.<a id=\"after_i\"></a>\n",
    "\n",
    "My goal with the cosine similarity matrix was to create a feature for the website to allow users to view dresses similar to the ones they like. My hope was that, within the convolutions of the neural network, some dress features other than color might be captured (i.e. length, fabric texture, sheen). I looked at a few examples, and this appears to have been successful.\n",
    "\n",
    "Below, I chose a long, champagne-colored, sequine dress (outlined image top left). The top most similar dresses from the matrix were all long, very similar in color, several with some sort of sheen, texture, or sequins.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.10.49+PM.png\" style=\"width:600;\">\n",
    "\n",
    "In the second test (below) I chose another long, sequin dress. This reference dress (outlined image top left) is navy, but the model misclassified it as black. Interestingly, all the most similar dresses from the cosine similarity matrix were correctly classified as navy. They were also long and some had sequins or lace.\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.10.59+PM.png\" style=\"width:600;\">\n",
    "\n",
    "The effectiveness of the cosine similarity matrix for finding similar dresses appears fairly successful. Performance on a larger scale still needs to be assessed. It would be useful to find the weak points in this feature, identifying at what number of dresses is there a noticeable divergence in style/color similarity. I imagine this will be heavily influenced by the number of dresses available in the reference dress color category.\n",
    "\n",
    "## Other Similar Products\n",
    "\n",
    "From hair accessories to statement jewelry all the way down to toenail polish and matching wedges, there is a lot more to a bridesmaid's ensemble than her dress alone. Likewise, groomsmen are expected to match, too (think bowties, suspenders, pocket squares, socks). With this in mind, I wanted to see if my convonet could be used on other wedding-party related products. \n",
    "\n",
    "I tested this theory on bowties first. Retail images for ties and bowties are usually focused on the product, with a simple background and not much other noise. Model_35 was very effective in identifying the color class of a small sample of bowties. The image below shows the bowtie and the model predicted color class. Further evaluation of effectiveness is warranted, and this looks like a very promising potential feature for the website!\n",
    "\n",
    "<img src=\"https://s3-us-west-2.amazonaws.com/capstoneinstructions/Screen+Shot+2017-05-30+at+5.11.22+PM.png\" style=\"width:600;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Future Work\n",
    "\n",
    "Using a convolutional neural network to classify dress images was an effecive approach for accomplishing my goals. Data collection, cleaning, and labeling was the most important and time-intensive part of the project. The final website provides many more color choices than typical online retailers, and it is a great starting point with potential for improvements in many areas.\n",
    "\n",
    "## Model Improvements\n",
    "\n",
    "### Data Collection, Label Cleaning\n",
    "Model performance is only as good as the data allows. The cleaner the data and better segmented the color classes, the better the model will perform. Likewise, more data will help performance.\n",
    "\n",
    "A Better Labeling Approach\n",
    "- Currently, I can only view dresses on the \"Admin Dresses\" site that have received a label from our website. To improve the data collection process, I'd like to create a tag for \"unlabeled\", which allows me to view all the images through my website and more quickly add labels to the database manually.\n",
    "\n",
    "Class Imbalance\n",
    "- Resolving some of the class imbalance may improve the performance of the convonet. I will need to collet and label more images in the lacking color classes.\n",
    "\n",
    "Background Subtraction/RGB Histograms\n",
    "- I may try applying background subtraction to the images, then labeling based on most frequent RGB values. I could use the images I already have in each color class to help identify RGB ranges for labeling.\n",
    "\n",
    "Label Like-Images\n",
    "- Leveraging the current data-set may also be possible for gathering more/better/different data. Instead of having people label with color swatches, they could select images with like-colors. This process could be used to label by color groups and could also be used for different types of convonet modeling.\n",
    "\n",
    "### More Models\n",
    "\n",
    "General Improvements\n",
    "- After collecting more data and improving the labels, I'd like to build a similar convonet that performs better than the current one. With more time and work, that is definitely possible.\n",
    "\n",
    "Localization/Similarity\n",
    "- A convonet that can identify the location of a dress (or other product) in an image could be very useful for this application. This would require a different kind of data labeling. With localization abilities and data on alike-images, it may be possible to build a model that can take in an image and return like-dresses.\n",
    "\n",
    "Transfer Learning\n",
    "- I may be able to achieve greater accuracy in labeling with transfer learning (i.e. using a pre-trained architecture like VGG-16 or Inception V3). I had originally intended to try this, which is why I chose 299x299 for my input image size. Overall, I don't think the improvements I would get from transfer learning would be worthwhile until the dataset is improved (cleaner labeling, more balanced classes).\n",
    "\n",
    "## Website Improvements\n",
    "\n",
    "I have a lot of ideas for improving the website which were not within the scope of the original project. Ideas for website improvement include:\n",
    "\n",
    "More retailers\n",
    "- Partnerships to eliminate need for scraping\n",
    "- Wider selection of dresses in general\n",
    "    \n",
    "Automated data collection process\n",
    "\n",
    "Special features (described above)\n",
    "- Click for similar dresses\n",
    "- Matching accessories (bowties etc.)\n",
    "\n",
    "Bride Accounts\n",
    "- Bride sets up her \"shop\" and invites bridesmaids\n",
    "       - chooses colors\n",
    "       - removes dresses she doesn't like\n",
    "- Drag and drop image slots to lock in purchased dresses\n",
    "- Image upload if a bridesmaid gets a dress somewhere else\n",
    "\n",
    "Color-coded like buttons (by bridesmaid)\n",
    "\n",
    "Channeled dress viewing\n",
    "- When a color is selected, it displays column-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Resources\n",
    "\n",
    "**Image Downloading**\n",
    "\n",
    "Bulk Download Images(ZIG): https://chrome.google.com/webstore/detail/bulk-download-imageszig/gfjhimhkjmipphnaminnnnjpnlneeplk?hl=en\n",
    "\n",
    "Fatkun Batch Download Image: https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf?hl=en\n",
    "\n",
    "\n",
    "**Stanford cs231 notes and lecture videos**\n",
    "\n",
    "http://cs231n.github.io/\n",
    "\n",
    "https://www.youtube.com/watch?v=yp9rwI_LZX8&index=1&list=PLjX3tKChumyCOstk6GO8PeEjwmcz7jWia\n",
    "\n",
    "**Keras tutorial**\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
